import os
import pandas as pd
import numpy as np
import yaml
import json
import matplotlib.pyplot as plt
from sklearn.ensemble import IsolationForest
from prophet import Prophet
from datetime import datetime, timedelta


# 1. **Ingest Metrics Data**

def load_metrics_data(metrics_folder):
    metrics_data = []
    for file in os.listdir(metrics_folder):
        if file.endswith(".csv"):
            file_path = os.path.join(metrics_folder, file)
            df = pd.read_csv(file_path)
            metrics_data.append(df)
    return pd.concat(metrics_data, ignore_index=True)


# 2. **Load SLO Targets**

def load_slo_targets(slo_target_file):
    with open(slo_target_file, 'r') as f:
        slo_targets = yaml.safe_load(f)
    return slo_targets


# 3. **Load System Topology**

def load_topology(topology_file):
    with open(topology_file, 'r') as f:
        topology = json.load(f)
    return topology


# 4. **Preprocess Metrics Data**

def preprocess_metrics(metrics_df):
    metrics_df['timestamp'] = pd.to_datetime(metrics_df['timestamp'])
    metrics_df.set_index('timestamp', inplace=True)
    return metrics_df


# 5. **Detect Drift** (Anomaly Detection)

def detect_drift(metrics_df, column, threshold=2.0):
    # Using Isolation Forest for anomaly detection
    model = IsolationForest(contamination=0.1)
    metrics_df['anomaly'] = model.fit_predict(metrics_df[[column]])
    drift_points = metrics_df[metrics_df['anomaly'] == -1]
    return drift_points


# 6. **Forecast Breach Using Prophet**

def forecast_breach(metrics_df, column, slo_target, forecast_horizon=24):
    # Prepare the data for Prophet
    df_prophet = metrics_df[['timestamp', column]].reset_index()
    df_prophet.columns = ['ds', 'y']

    model = Prophet()
    model.fit(df_prophet)

    future = model.make_future_dataframe(df_prophet, periods=forecast_horizon, freq='H')
    forecast = model.predict(future)

    # Forecast chart
    plt.figure(figsize=(10, 6))
    model.plot(forecast)
    plt.axhline(y=slo_target, color='r', linestyle='--', label='SLO Target')
    plt.title(f'{column} Forecast with SLO Target')
    plt.legend()
    plt.show()

    # Check if a breach is forecasted
    forecasted_values = forecast[['ds', 'yhat']].tail(forecast_horizon)
    forecasted_values['breach'] = forecasted_values['yhat'] > slo_target
    return forecasted_values


# 7. **Generate Mitigation Plan**

def generate_mitigation_plan(drift_points, forecasted_values, slo_target, topology):
    mitigation_plan = []

    # Check if drift points are significant
    if not drift_points.empty:
        for idx, row in drift_points.iterrows():
            mitigation_plan.append({
                'action': 'Investigate drift',
                'details': f"Anomaly detected in {row.name}, metric exceeded threshold"
            })

    # If forecast predicts breach
    if forecasted_values['breach'].any():
        mitigation_plan.append({
            'action': 'Scale resources',
            'details': 'Scale services to handle increased load'
        })
        # Add topology-based mitigations (simplified)
        if 'critical_service' in topology:
            mitigation_plan.append({
                'action': 'Adjust load balancing',
                'details': f"Re-route traffic away from {topology['critical_service']}"
            })
    return mitigation_plan


# 8. **Output the Results**

def output_results(forecasted_values, mitigation_plan):
    print("\n--- Forecasted Values ---")
    print(forecasted_values)

    print("\n--- Mitigation Plan ---")
    for mitigation in mitigation_plan:
        print(f"{mitigation['action']}: {mitigation['details']}")


# 9. **Main Workflow**

def main():
    # Paths to input files
    metrics_folder = './metrics'
    slo_target_file = './slo_targets.yml'
    topology_file = './topology.json'

    # Load the data
    metrics_df = load_metrics_data(metrics_folder)
    slo_targets = load_slo_targets(slo_target_file)
    topology = load_topology(topology_file)

    # Preprocess metrics data
    metrics_df = preprocess_metrics(metrics_df)

    # Loop over the slo targets
    for service, slo_target in slo_targets.items():
        print(f"\nAnalyzing SLO for {service}...")
        column = slo_target['metric']
        slo_value = slo_target['value']

        # 1. Drift Detection
        drift_points = detect_drift(metrics_df, column)

        # 2. Forecasting breach
        forecasted_values = forecast_breach(metrics_df, column, slo_value)

        # 3. Mitigation Plan
        mitigation_plan = generate_mitigation_plan(drift_points, forecasted_values, slo_value, topology)

        # 4. Output the results
        output_results(forecasted_values, mitigation_plan)


if __name__ == '__main__':
    main()